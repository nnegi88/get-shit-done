---
phase: 01-test-safety-net
plan: 04
type: execute
wave: 2
depends_on: ["01-01"]
files_modified:
  - bin/install.test.js
  - hooks/hooks.test.js
  - package.json
autonomous: true

must_haves:
  truths:
    - "Running the test suite exercises all 3 installer runtime targets (Claude Code, OpenCode, Gemini CLI) for install paths"
    - "Upgrade path detection works correctly for existing installations"
    - "Hook scripts can be loaded and their exports tested without side effects"
    - "npm test runs all test files (gsd-tools, install, hooks) in a single command"
  artifacts:
    - path: "bin/install.test.js"
      provides: "Runtime integration tests for install.js"
      min_lines: 450
    - path: "hooks/hooks.test.js"
      provides: "Lightweight behavioral tests for hook scripts"
      min_lines: 40
    - path: "package.json"
      provides: "Updated test scripts for multi-file test running"
      contains: "install.test.js"
  key_links:
    - from: "bin/install.test.js"
      to: "bin/install.js"
      via: "subprocess invocation for install integration tests"
      pattern: "execSync.*install\\.js"
    - from: "package.json"
      to: "bin/install.test.js"
      via: "npm test script"
      pattern: "install\\.test\\.js"
    - from: "package.json"
      to: "hooks/hooks.test.js"
      via: "npm test script"
      pattern: "hooks\\.test\\.js"
---

<objective>
Add install.js runtime integration tests for all 3 targets, lightweight hook tests, and update npm test scripts to run all test files.

Purpose: Plan 01 tested install.js pure functions in isolation. This plan tests the install() function's integration behavior -- that it produces correct file structures for each runtime target (Claude Code, OpenCode, Gemini CLI). It also adds minimal hook coverage and wires everything into `npm test`.

Output: Runtime integration tests in `bin/install.test.js`, hook tests in `hooks/hooks.test.js`, updated `package.json` scripts.
</objective>

<execution_context>
@/Users/naveennegi/.claude/get-shit-done/workflows/execute-plan.md
@/Users/naveennegi/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@bin/install.js
@hooks/gsd-check-update.js
@hooks/gsd-statusline.js
@package.json
@.planning/phases/01-test-safety-net/01-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add installer runtime integration tests (TEST-01)</name>
  <files>bin/install.test.js</files>
  <action>
  Add integration tests to `bin/install.test.js` (which already has pure function tests from Plan 01). These tests invoke the installer targeting temp directories to verify file structure output.

  **Testing approach**: Use subprocess invocation (`execSync`) to run `node bin/install.js` with flags that bypass interactive prompts. Point the install at temp directories to avoid modifying the real system. The installer supports `--claude`, `--opencode`, `--gemini` flags and `--global`/`--local` to skip the interactive prompt.

  **`describe('installer runtime integration', ...)`**

  For each runtime, test the install path by running the installer subprocess targeting a temp directory structure:

  `describe('claude runtime install', ...)` (3-4 tests):
  1. Global install creates expected directory structure (commands/gsd/, agents/, settings.json or CLAUDE.md)
  2. Verify agent files have correct Claude frontmatter format (---\nname:...\n---)
  3. Verify command files are copied with correct content
  4. Upgrade path: pre-populate the target with older files, run install, verify files are updated

  `describe('opencode runtime install', ...)` (3-4 tests):
  1. Global install creates expected .opencode directory structure
  2. Verify agent files have OpenCode frontmatter format (tools object, no name field)
  3. Verify settings.json is valid JSONC with correct schema
  4. Upgrade path: verify existing custom content is preserved during upgrade

  `describe('gemini runtime install', ...)` (3-4 tests):
  1. Global install creates expected .gemini directory structure
  2. Verify agent files have Gemini YAML format (tools as array with gemini tool names)
  3. Verify TOML command files have correct format
  4. Upgrade path: verify existing content preserved

  `describe('installer edge cases', ...)` (3-4 tests):
  1. --global and --local together produces error message
  2. --uninstall without --global or --local produces error message
  3. Non-interactive terminal (stdin not TTY) defaults to Claude global install
  4. Content verification: at least one agent file per runtime has expected structure

  **Implementation notes:**
  - Set up temp directories that mimic global config locations. Use environment variables or `--config-dir` flag if available to redirect install target.
  - If `--config-dir` is not available, you may need to mock the home directory or test at a higher level by checking what files the installer WOULD create by examining the install function's behavior.
  - If subprocess testing is too fragile for the install integration (e.g., the installer always writes to the real home directory), fall back to testing the `install()` function directly using the module.exports from Plan 01, passing in a temp directory path. Check if `install()` accepts a target directory parameter. If not, use the `getGlobalDir()` function to understand where it writes, and mock accordingly.
  - The key constraint is TEST-01: "all 3 runtime targets exercised for install and upgrade paths."

  Total: ~12-16 tests.
  </action>
  <verify>Run `node --test bin/install.test.js --test-name-pattern "installer runtime|claude runtime|opencode runtime|gemini runtime"` and confirm all runtime integration tests pass.</verify>
  <done>All 3 runtime targets (Claude, OpenCode, Gemini) have install path tests. At least one upgrade path test exists per runtime. Generated config files verified for correct format.</done>
</task>

<task type="auto">
  <name>Task 2: Add hook tests and update npm test scripts</name>
  <files>hooks/hooks.test.js, package.json</files>
  <action>
  **Part A: Create hooks/hooks.test.js**

  Create lightweight behavioral tests for the 2 hook scripts. Hooks are small (62 and 91 lines) and run as subprocess scripts invoked by the IDE.

  ```javascript
  const { test, describe } = require('node:test');
  const assert = require('node:assert');
  const { execSync } = require('child_process');
  const path = require('path');
  ```

  `describe('gsd-check-update hook', ...)` (3-4 tests):
  1. Script loads without error: `node -e "require('./hooks/gsd-check-update.js')"` or `node hooks/gsd-check-update.js` exits cleanly
  2. Handles missing package.json gracefully (run in empty temp dir)
  3. Output format is correct (captures stdout format for characterization)

  `describe('gsd-statusline hook', ...)` (3-4 tests):
  1. Script loads without error
  2. Handles missing .planning directory gracefully
  3. Output format when .planning exists (statusline string)
  4. Output format when .planning is absent (empty or default)

  Note: Hooks may require specific environment setup. Test what you can -- the goal is behavioral characterization, not 100% path coverage. If a hook requires the full IDE environment, test the "no IDE" path (graceful degradation) and document what can't be tested.

  Total: 5-8 tests.

  **Part B: Update package.json test scripts**

  Update the `scripts` section in `package.json`:

  ```json
  "scripts": {
    "build:hooks": "node scripts/build-hooks.js",
    "prepublishOnly": "npm run build:hooks",
    "test": "node --test get-shit-done/bin/gsd-tools.test.js bin/install.test.js hooks/hooks.test.js",
    "test:tools": "node --test get-shit-done/bin/gsd-tools.test.js",
    "test:install": "node --test bin/install.test.js",
    "test:hooks": "node --test hooks/hooks.test.js",
    "test:filter": "node --test --test-name-pattern"
  }
  ```

  This ensures `npm test` runs all 3 test files. Individual test scripts allow focused development.
  </action>
  <verify>
  Run `npm test` and confirm it executes all 3 test files (gsd-tools.test.js, install.test.js, hooks.test.js) and all tests pass.
  Run `npm run test:hooks` and confirm hook tests pass independently.
  Run `npm run test:install` and confirm install tests pass independently.
  </verify>
  <done>Hook scripts have behavioral tests. `npm test` runs all test files. Individual test:* scripts work for focused development. Total test count across all files is 250+.</done>
</task>

</tasks>

<verification>
1. `npm test` runs all 3 test files and all tests pass
2. All 3 runtime targets (Claude, OpenCode, Gemini) have install tests per TEST-01
3. At least one upgrade path test per runtime
4. Hook scripts have behavioral tests
5. `npm run test:tools`, `npm run test:install`, `npm run test:hooks` all work independently
6. Total test count across all files is 250+
</verification>

<success_criteria>
- All 3 installer runtime targets exercised for install and upgrade paths (TEST-01)
- Hook scripts have lightweight behavioral tests
- npm test runs all test files in a single command
- Individual test scripts available for focused development
- Total test count across all 3 files is 250+
- All tests pass on `npm test`
</success_criteria>

<output>
After completion, create `.planning/phases/01-test-safety-net/01-04-SUMMARY.md`
</output>
