---
phase: 01-test-safety-net
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - get-shit-done/bin/gsd-tools.test.js
autonomous: true

must_haves:
  truths:
    - "Every standalone command (resolve-model, find-phase, generate-slug, current-timestamp, list-todos, verify-path-exists, config-ensure-section, config-set) has at least one characterization test"
    - "All 11 state subcommands (load, update, get, patch, advance-plan, record-metric, update-progress, add-decision, add-blocker, resolve-blocker, record-session) have characterization tests"
    - "Each tested command captures its stdout/stderr/exit code contract"
  artifacts:
    - path: "get-shit-done/bin/gsd-tools.test.js"
      provides: "Characterization tests for standalone and state commands"
      min_lines: 2800
  key_links:
    - from: "get-shit-done/bin/gsd-tools.test.js"
      to: "get-shit-done/bin/gsd-tools.js"
      via: "execSync subprocess invocation"
      pattern: "runGsdTools\\("
---

<objective>
Add characterization tests for all untested standalone commands (Tier 1) and state subcommands (Tier 2) in gsd-tools.js.

Purpose: These are the simplest, highest-volume untested commands. Capturing their behavior now creates a safety net for the monolith decomposition in Phase 3. Standalone commands and state subcommands are independent of each other, making them natural to test together.

Output: ~40-55 new tests added to `get-shit-done/bin/gsd-tools.test.js`.
</objective>

<execution_context>
@/Users/naveennegi/.claude/get-shit-done/workflows/execute-plan.md
@/Users/naveennegi/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@get-shit-done/bin/gsd-tools.js
@get-shit-done/bin/gsd-tools.test.js
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add characterization tests for Tier 1 standalone commands</name>
  <files>get-shit-done/bin/gsd-tools.test.js</files>
  <action>
  Add describe blocks for each untested standalone command, appending after the existing describe blocks. Follow the existing test pattern: `createTempProject()` in beforeEach, `cleanup()` in afterEach, `runGsdTools()` to invoke, assert on output JSON or stderr.

  **`describe('resolve-model command', ...)`** (2 tests):
  1. Valid agent type returns expected model mapping
  2. Unknown agent type returns default/fallback

  **`describe('find-phase command', ...)`** (3 tests):
  1. Finds existing phase directory by number
  2. Returns not-found for missing phase number
  3. Finds decimal phase directory (e.g., `01.1-inserted`)

  **`describe('generate-slug command', ...)`** (3 tests):
  1. Basic text generates lowercase hyphenated slug
  2. Special characters stripped or replaced
  3. Empty/whitespace-only input handled gracefully

  **`describe('current-timestamp command', ...)`** (2 tests):
  1. Default format returns ISO-like timestamp string (use pattern match, not exact value)
  2. With format argument returns formatted output

  **`describe('list-todos command', ...)`** (3 tests):
  1. Empty project returns empty array
  2. With TODO files returns list
  3. Filtered by status if supported

  **`describe('verify-path-exists command', ...)`** (2 tests):
  1. Existing path returns `{ exists: true }`
  2. Non-existent path returns `{ exists: false }`

  **`describe('config-ensure-section command', ...)`** (3 tests):
  1. Creates section in new config
  2. Idempotent on existing section
  3. Handles malformed or missing config.json gracefully

  **`describe('config-set command', ...)`** (3 tests):
  1. Sets value in existing config
  2. Sets nested key path
  3. Creates config if missing

  Each test follows the existing pattern. For commands that return JSON, parse and assert specific fields. For commands with non-deterministic output (current-timestamp), use pattern assertions (`assert.ok(output.match(...))`).

  Total: ~21 new tests.
  </action>
  <verify>Run `node --test get-shit-done/bin/gsd-tools.test.js --test-name-pattern "resolve-model|find-phase|generate-slug|current-timestamp|list-todos|verify-path|config-ensure|config-set"` and confirm all new tests pass without breaking existing tests.</verify>
  <done>All 8 standalone commands have characterization tests capturing their stdout/stderr/exit code contract.</done>
</task>

<task type="auto">
  <name>Task 2: Add characterization tests for Tier 2 state subcommands</name>
  <files>get-shit-done/bin/gsd-tools.test.js</files>
  <action>
  Add a `describe('state subcommands', ...)` block (or individual describe blocks per subcommand) for all 11 state subcommands. The existing test file already has a `state-snapshot` describe block -- these are DIFFERENT subcommands.

  **`describe('state load command', ...)`** (3 tests):
  1. Returns config and state when both exist (create config.json + STATE.md in tmpDir)
  2. Returns defaults when config missing
  3. Returns state fields parsed from STATE.md content

  **`describe('state update command', ...)`** (2 tests):
  1. Updates valid field in STATE.md
  2. Handles missing STATE.md gracefully (creates or errors)

  **`describe('state get command', ...)`** (2 tests):
  1. Returns full state JSON
  2. Returns specific section when argument provided

  **`describe('state patch command', ...)`** (2 tests):
  1. Applies single patch to STATE.md
  2. Applies multiple patches in sequence

  **`describe('state advance-plan command', ...)`** (2 tests):
  1. Advances plan number in state (e.g., plan 1 -> 2)
  2. Works from initial state (plan 0 -> 1)

  **`describe('state record-metric command', ...)`** (2 tests):
  1. Records metric with full options (duration, context)
  2. Records metric with minimal options

  **`describe('state update-progress command', ...)`** (2 tests):
  1. Updates progress bar when phases exist
  2. Handles empty phases directory

  **`describe('state add-decision command', ...)`** (2 tests):
  1. Adds decision with phase context
  2. Adds decision without phase context

  **`describe('state add-blocker command', ...)`** (2 tests):
  1. Adds new blocker to state
  2. Handles duplicate blocker text

  **`describe('state resolve-blocker command', ...)`** (2 tests):
  1. Resolves existing blocker
  2. Handles non-existent blocker gracefully

  **`describe('state record-session command', ...)`** (2 tests):
  1. Records session with full options (timestamp, phase, status)
  2. Records session with minimal options

  For each test: create appropriate STATE.md content with the format the command expects, run the command, verify the output JSON and/or the modified STATE.md file content.

  Total: ~23 new tests.
  </action>
  <verify>Run `node --test get-shit-done/bin/gsd-tools.test.js --test-name-pattern "state "` and confirm all state subcommand tests pass. Then run the full suite `node --test get-shit-done/bin/gsd-tools.test.js` to confirm no regressions.</verify>
  <done>All 11 state subcommands have characterization tests. Running the full test suite passes with 75 + ~44 = ~119 tests.</done>
</task>

</tasks>

<verification>
1. `node --test get-shit-done/bin/gsd-tools.test.js` passes with all existing + new tests
2. Every Tier 1 command listed has at least one test in a describe block
3. Every Tier 2 state subcommand has at least one test
4. No existing test has been modified or broken
5. Total new test count is ~40-55
</verification>

<success_criteria>
- All 8 standalone commands have characterization tests
- All 11 state subcommands have characterization tests
- Full test suite passes with ~115-130 total tests
- No existing tests broken or modified
- Each test captures the observable contract (stdout JSON, stderr, exit code)
</success_criteria>

<output>
After completion, create `.planning/phases/01-test-safety-net/01-02-SUMMARY.md`
</output>
