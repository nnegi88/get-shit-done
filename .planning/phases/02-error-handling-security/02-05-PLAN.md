---
phase: 02-error-handling-security
plan: 05
type: tdd
wave: 3
depends_on: ["02-01", "02-02", "02-03", "02-04"]
files_modified:
  - get-shit-done/bin/gsd-tools.test.js
autonomous: true

must_haves:
  truths:
    - "Tests verify error classes exist and carry correct exit codes"
    - "Tests verify input validation rejects bad phase numbers, field names, and JSON strings"
    - "Tests verify path traversal attempts are rejected"
    - "Tests verify prototype pollution keys are stripped from JSON.parse results"
    - "Tests verify empty catch blocks no longer exist"
    - "All existing tests plus new tests pass together"
  artifacts:
    - path: "get-shit-done/bin/gsd-tools.test.js"
      provides: "Phase 2 integration tests"
      contains: "describe('Phase 2: Error Handling"
  key_links:
    - from: "test file"
      to: "gsd-tools.js error classes"
      via: "subprocess execution and exit code verification"
      pattern: "exitCode.*[2-4]"
---

<objective>
Add TDD-style integration tests verifying all Phase 2 changes work end-to-end: error classes, exit codes, input validation, security hardening.

Purpose: Capture the new behaviors introduced in Phase 2 as permanent characterization tests. These tests protect Phase 3 (decomposition) from regressions when the monolith is split.
Output: New test section in gsd-tools.test.js covering Phase 2 requirements.
</objective>

<execution_context>
@/Users/naveennegi/.claude/get-shit-done/workflows/execute-plan.md
@/Users/naveennegi/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@get-shit-done/bin/gsd-tools.test.js
@get-shit-done/bin/gsd-tools.js
@.planning/phases/02-error-handling-security/02-01-SUMMARY.md
@.planning/phases/02-error-handling-security/02-02-SUMMARY.md
@.planning/phases/02-error-handling-security/02-03-SUMMARY.md
@.planning/phases/02-error-handling-security/02-04-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Write tests for error classes, exit codes, and input validation</name>
  <files>get-shit-done/bin/gsd-tools.test.js</files>
  <action>
    Add a new describe block at the end of gsd-tools.test.js: `describe('Phase 2: Error Handling & Security')`.

    Use the existing `runGsdTools(args, cwd)` test helper pattern (subprocess execution, capture stdout/stderr/exit code).

    **Test group 1: POSIX exit codes (ERRH-03)**
    - Test that missing required args returns exit code 2 (not 1):
      - `generate-slug` with no args -> exit 2
      - `find-phase` with no args -> exit 2
      - `frontmatter get` with no file -> exit 2
    - Test that config errors return exit code 3:
      - `state load` with no .planning/ directory -> exit 3
    - Test that the error message format is preserved ("Error: ..." on stderr)

    **Test group 2: Input validation (SECU-01)**
    - Test bad phase number rejection:
      - `find-phase abc` -> exit 2, stderr contains "Invalid phase number"
      - `find-phase ../../../etc` -> exit 2, stderr contains "Invalid phase number"
    - Test bad field name rejection:
      - `state update __proto__ hack` (in temp project) -> exit 2, stderr contains "Invalid field name"
    - Test bad JSON rejection:
      - `frontmatter merge <file> --data {bad}` -> exit 2, stderr contains "Invalid JSON"

    **Test group 3: Path traversal rejection (SECU-02)**
    - Test path outside project root:
      - `frontmatter get ../../etc/passwd` (in temp project) -> error about path scope
    - Test absolute path outside project:
      - `frontmatter get /etc/passwd` (in temp project) -> error about path scope
    - NOTE: Use temp directory as cwd for these tests

    **Test group 4: Empty catch verification (ERRH-01)**
    - Test that gsd-tools.js contains zero `catch {}` patterns:
      - Read file content, count `catch {}` occurrences, assert 0
    - Test that all catches have `(e)` parameter:
      - Count `catch (e)` occurrences, assert >= 30

    **Test group 5: Security utilities exist (SECU-03, SECU-04)**
    - Test that escapeRegExp is used (grep source for function and usages)
    - Test that sanitizeJson is used (grep source for function and usages)

    Follow existing test patterns exactly:
    - Use `createTempProject()` for temp dirs
    - Use `cleanup(tmpDir)` in afterEach
    - Use `assert.strictEqual` for exit codes
    - Use `assert.ok` for boolean checks

    Target: 15-20 new tests covering the 5 Phase 2 success criteria.
  </action>
  <verify>Run `node --test get-shit-done/bin/gsd-tools.test.js` -- all tests pass including the new ones.</verify>
  <done>15-20 new tests exist covering error classes, POSIX exit codes, input validation, path traversal, empty catch elimination, and security utilities. All tests pass.</done>
</task>

</tasks>

<verification>
1. `node --test get-shit-done/bin/gsd-tools.test.js` passes all tests (old + new)
2. `node --test bin/install.test.js` still passes (no install.js test changes)
3. New tests specifically validate the 5 Phase 2 success criteria
</verification>

<success_criteria>
- New test section exists in gsd-tools.test.js
- Tests cover all 5 Phase 2 success criteria
- 15-20 new tests added
- All tests (old + new) pass
- Tests use existing helper patterns (createTempProject, runGsdTools, cleanup)
</success_criteria>

<output>
After completion, create `.planning/phases/02-error-handling-security/02-05-SUMMARY.md`
</output>
